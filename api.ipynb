{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad641c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile\n",
    "import joblib\n",
    "import re\n",
    "import string\n",
    "import base64\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import jupytext\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "model = joblib.load(\"model.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "\n",
    "app = FastAPI(title=\"Email Spam Detection\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "def extract_email(raw_email):\n",
    "     email_text = re.findall(\n",
    "            r\"Content-Type:\\s*text/plain;[^\\n\\r]*[\\r\\n]+Content-Transfer-Encoding:\\s*[^\\n\\r]+[\\r\\n]+([\\s\\S]*?)(?=\\n--|\\r--|$)\",\n",
    "            raw_email,\n",
    "            re.DOTALL | re.IGNORECASE\n",
    "        )\n",
    "     extracted_text = \"\"\n",
    "     for row in email_text:\n",
    "        row = row.strip()\n",
    "        try:\n",
    "            decoded_text = base64.b64decode(row.strip()).decode(\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            decoded_text = row\n",
    "        extracted_text += decoded_text + \"\\n\"\n",
    "     return extracted_text.strip()\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def extract_url(extracted_text):\n",
    "    urls = re.findall(r\"(https?://[^\\s]+|www\\.[^\\s]+)\", extracted_text)\n",
    "    return urls\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "def extract_images(raw_email, save_dir =\"attachments/extracted_images\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    image_all_info = re.findall(\n",
    "            r\"Content-Type:\\s*image\\/[^\\n\\r]+[\\s\\S]*?(?=\\n--|\\r--|$)\",\n",
    "            raw_email,\n",
    "            re.DOTALL | re.IGNORECASE,\n",
    "        )\n",
    "    extracted_img = []\n",
    "    for i, part in enumerate(image_all_info, start= 1):\n",
    "        split_image = re.search(r\"\\r?\\n\\s*\\r?\\n\", part)\n",
    "        if not split_image:\n",
    "            continue\n",
    "        split_index = split_image.start()\n",
    "        header = part[:split_index].strip()\n",
    "        encoded_image = part[split_image.end():].strip()\n",
    "        img_name = re.search(r'filename=[\"\\']([^\"\\']+)[\"\\']', header, re.IGNORECASE)\n",
    "        if img_name:\n",
    "            image_name = img_name.group(1)\n",
    "        else:\n",
    "            image_name = f\"image{i}.png\"\n",
    "        encoded_image = re.sub(r'\\s+', '', encoded_image)\n",
    "        image_bytes = base64.b64decode(encoded_image)\n",
    "        file_path = os.path.join(save_dir, image_name)\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(image_bytes)\n",
    "        extracted_img.append({\n",
    "            \"filename\": image_name,\n",
    "            \"encoded_image\": encoded_image,\n",
    "            \"path\": str(file_path)\n",
    "            })\n",
    "    return extracted_img  \n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "def extract_files(raw_email, save_dir =\"attachments/extracted_files\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_all_info = re.findall(\n",
    "            r\"Content-Type:\\s*application\\/[^\\n\\r]+[\\s\\S]*?(?=\\r?\\n--|\\r?--|$)\",\n",
    "            raw_email,\n",
    "            re.DOTALL | re.IGNORECASE,\n",
    "        )\n",
    "    extracted_files = []\n",
    "    for i, part in enumerate(file_all_info, start= 1):\n",
    "        split_file = re.search(r\"\\r?\\n\\s*\\r?\\n\", part)\n",
    "        if not split_file:\n",
    "            continue\n",
    "        split_index = split_file.start()\n",
    "        header = part[:split_index].strip()\n",
    "        encoded_file = part[split_file.end():].strip()\n",
    "        file_name = re.search(r'filename=[\"\\']([^\"\\']+)[\"\\']', header, re.IGNORECASE)\n",
    "        if file_name:\n",
    "            fileName = file_name.group(1)\n",
    "        else:\n",
    "            fileName = f\"file{i}\"\n",
    "        encoded_file = re.sub(r'\\s+', '', encoded_file)\n",
    "        file_bytes = base64.b64decode(encoded_file)\n",
    "        file_path = os.path.join(save_dir, fileName)\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(file_bytes)\n",
    "        extracted_files.append({\n",
    "            \"filename\": fileName,\n",
    "            \"encoded_file\": encoded_file,\n",
    "            \"path\": str(file_path)\n",
    "            })\n",
    "    return extracted_files\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def clean_email(extracted_text):\n",
    "    extracted_text = extracted_text.lower()\n",
    "    extracted_text = re.sub(r'http\\S+|www.\\S+', '', extracted_text)\n",
    "    extracted_text = extracted_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    extracted_text = re.sub(r'\\d+', '', extracted_text)\n",
    "    words = extracted_text.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    email_clean = \" \".join(words)\n",
    "    return email_clean\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict_email(file: UploadFile = File(...)):\n",
    "    raw_text = await file.read()\n",
    "    raw_email = raw_text.decode(\"utf-8\", errors= \"ignore\")\n",
    "    extracted_text = extract_email(raw_email)\n",
    "\n",
    "    urls = extract_url(extracted_text)\n",
    "\n",
    "    images = extract_images(raw_email)\n",
    "    files = extract_files(raw_email)\n",
    "\n",
    "    cleaned = clean_email(extracted_text)\n",
    "\n",
    "    x = vectorizer.transform([cleaned])\n",
    "    prediction = model.predict(x)[0]\n",
    "    if prediction == 1:\n",
    "        result = \"Spam\" \n",
    "    else:\n",
    "        result = \"Not Spam\"\n",
    "\n",
    "    return {\n",
    "        \"prediction\": result,\n",
    "        \"num_urls\": len(urls),\n",
    "        \"urls\": urls,\n",
    "        \"num_images\": len(images),\n",
    "        \"images\": [{\"filename\":img[\"filename\"], \"encoded_image\":img[\"encoded_image\"]} for img in images],\n",
    "        \"num_files\": len(files),\n",
    "        \"files\": [{\"filename\":file[\"filename\"], \"encoded_file\":file[\"encoded_file\"]} for file in files],\n",
    "        \"text_preview\": cleaned[:300]\n",
    "    }\n",
    "jupytext --to notebook api.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db710dd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
